\documentclass[12pt, letterpaper, twocolumn]{article}
\usepackage[margin=1.0in]{geometry}
\usepackage{fontspec}
\setmainfont{Arial}
\usepackage{fancyhdr}
\setlength{\headheight}{14.5pt}
\usepackage{graphicx}
\usepackage{caption}
\captionsetup[figure]{font=small}
\usepackage{amsmath}
\usepackage[]{siunitx}
\usepackage[style=numeric,sorting=none]{biblatex}
\addbibresource{refs.bib}
\pagestyle{fancy}
\fancyhf{}
\lhead{Iniyan Joseph} % change this to your actual name
\rhead{University of Texas at Dallas} % same for your university
\rfoot{\thepage}

\begin{document}
	
	% title
	\begin{center}
		\textbf{PropType: Everyday Objects as Typing Surfaces in Augmented Reality}
	\end{center}
	
	%% #set text(size: 12pt, font: "New Computer Modern")
	%% #set par(leading:0.7em)//, trailing:-0.3em)
	
	In the field of AR, achieving efficient text input remains a significant challenge. Although state-of-the-art head-mounted displays (HMDs) are equipped with reliable hand-held controllers and hand-tracking, they are rarely optimized for text-heavy tasks that demand high performance. Popular typing strategies in commercialized HMDs \cite{speicher2018selectionbased, xu2019pointSelectMethodsAR, Luong_2023_ControllersorBareHands} are often limited by collision-based input methods that require exaggerated mid-air movements. Bare-hand typing exacerbates this issue due to the lack of haptic feedback, resulting in poor key confirmation and diminished typing accuracy. Additionally, gesture-based input methods, whether using bare hands or controllers, causes significant muscle fatigue in the shoulders and forearms \cite{hansberger2017gorillaarm}. These limitations highlight the need for more efficient text entry solutions specifically designed for AR environments. 
	
	Many researchers have explored methods to improve typing performance with both speed and accuracy in virtual environments. These approaches include using controllers for discrete taps or continuous strokes as well as bare-hand input techniques, such as two-thumb or ten-finger typing \cite{Kim_2023_STAR, speicher2018selectionbased, Yu_et_al_2018}. While these methods build on familiar input skills, their performance is often limited due to the constraints of cursor-based typing and hand-tracking technologies embedded in commercialized HMDs. Some efforts have turned to external devices to enhance typing performance by leveraging users' proficiency with traditional input tools. However, while these devices can improve typing performance, they can disrupt the immersive and fluid experience that AR and VR aim to provide. This trade-off between high typing efficiency and seamless interaction remains a key challenge in AR and VR contexts. By integrating touch input and text entry on physical surfaces of everyday objects, we offer new insights into using everyday objects for complex input tasks.
	
	In our first study, our goal was to observe users' natural interactions with objects for typing. This offered insights into the ergonomic and user adaptations to different surfaces. I asked participants to freely explore feasible typing strategies on the props using a list of twenty-five sentences \cite{MacKenzie_2003_Phrases}. While interacting with each prop, I instructed participants described their typing strategies, experiences, and expectations. Upon completing the exploration phase, they completed a questionnaire to provide their preferences and subjective feedback. 
	
	I then analyzed their feedback and typing strategies to determine the objects used for the following study. Overall participants consistently favored small, easy-to-hold props with rigid surfaces that provide clear tactile responses during tapping, supported by the rankings. 
	
	Based on these results, we selected four of the objects in the first study, to cover a range of object geometries. The second study evaluated typing reachability and efficiency across four distinct props, each representing a range of sizes and shapes. For each of the four objects, the HMD displayed a grid of virtual spheres along the object's surface. At a time, a random button was highlighted. I instructed participants to quickly and accurately touch the highlighted sphere with their thumbtip. The sphere's color then changed, and, after a pause, a different sphere would become highlighted. 
	
	The time taken to reach each target was measured, and for each of the objects, a simple polygon was selected as the viable area for typing based on the mean performance for those points. typing pic From the customized keyboard layouts, I conducted another study testing PropType’s overall typing performance. Here, I asked participants to type randomly selected MacKenzie phrases. We achieved high speed and accuracy (26.1 WPM and 2.2\% CER) demonstrate the system’s practical use in AR environments.
	
	Finally, we gave participants from the  the ability to add their own sound and visual effects to provide stronger key confirmation and create a more immersive visual experience. I interviewed participants on their experiences. Participants felt that the ability to customize their typing experience improved their performance and enjoyment of typing on everyday objects. 
	
	Our results show the potential of typing on the surface of objects. Currently, the PropType system uses high fidelity optical tracking to track objects and fingers. Although this is accurate, it presents certain limitations. Future work may focus on mobility in AR typing scenarios, mimicking the initial study. Additionally, the effects of irregular geometries and strong touch feedback using AR must be explored further. Throughout the process, I conducted the user studies, designed the procedure for each of the studies, analyzed participant data, and helped draft the major sections of the paper. I also read the literature deeply, and wrote the related works and introduction sections and proposed the various future research directions.
	
	%% #set text(size:10pt)
	%% #bibliography("refs.bib")
	
	\noindent\textbf{References}
	\vspace{-0.125in}
	\printbibliography[heading=none]
	
\end{document}
